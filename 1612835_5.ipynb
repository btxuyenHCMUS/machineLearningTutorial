{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 5\n",
    "Bùi Trọng Xuyến - 1612835"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 1: Linear Regression error\n",
    "Trong mô hình hồi quy tuyến tính, thì việc tìm ra $w$ chỉ mang tính xấp xỉ dữ liệu $y = w^{*T}x + \\epsilon$.\n",
    "\n",
    "Với mỗi tập dữ liệu huấn luyện khác nhau thì việc tìm ra $w_{lin}$ sẽ tạo ra độ lỗi khác nhau. Và theo như đề bài thì:\n",
    "\n",
    "$\\mathbb{E}_{\\mathcal{D}}[\\mathbf{E}_{in}(\\mathbf{w}_{lin})] = \\sigma^{2}(1 - \\frac{d + 1}{N})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N =  10 => error =  0.001\n",
      "N =  25 => error =  0.006400000000000001\n",
      "N =  100 => error =  0.009100000000000002\n",
      "N =  500 => error =  0.009820000000000002\n",
      "N =  1000 => error =  0.009910000000000002\n"
     ]
    }
   ],
   "source": [
    "def q1(variance, d):\n",
    "    N = [10, 25, 100, 500, 1000]\n",
    "    \n",
    "    for n in N:\n",
    "        print(\"N = \", n, \"=> error = \", variance**2*(1 - (d + 1)/float(n)))\n",
    "\n",
    "#Show result of the question 1\n",
    "q1(0.1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo kết quả tính ra thì $N = 100$ là giá trị $N$ nhỏ nhất làm cho độ lỗi của tập train lớn hơn $0.008$\n",
    "\n",
    "Vậy đáp án chính xác là [c]. $100$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 2-3: Nonlinear Transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 2:**\n",
    "\n",
    "Phép nonlinear transform được ho trong đề là phép ánh xá từ không gian $\\mathcal{X}$ hai chiều (chưa thêm $x_{0} = 1$) sang không gian $\\mathcal{Z}$ hai chiều (chưa thêm $z_{0} = 1$): $$\\Phi(1, x_1, x_2) = (1, x_1^2, x_2^2)$$\n",
    "Với phép transform này thì tập hypothesis của mô hình perceptron (PLA) sẽ gồm các hypothesis có dạng:\n",
    "$$h(\\mathbf{x})=sign(\\tilde{w}_0 + \\tilde{w}_1 x_1^2 + \\tilde{w}_2 x_2^2)$$\n",
    "Mục tiêu của chúng ra là tìm ra các giá trị của $\\tilde{w}_1$ và $\\tilde{w}_2$ sao cho có hypothesis có dạng như hình vẽ.\n",
    "\n",
    "Ta suy luận như sau:\n",
    "\n",
    "- Ta có: $h(\\mathbf{x}) = sign(\\tilde{w}_0 + \\tilde{w}_1 x_1^2 + \\tilde{w}_2 x_2^2)$.\n",
    "- Cố định $x_1$, khi chúng ta làm giá trị $x_2$ càng dương hoặc càng âm thì $x_2^2$ càng dương, mà theo hình thì giá trị h(x) là (+) nên dấu của $\\tilde{w}_2$ phải dương.\n",
    "- Cố định $x_2$, khi chúng ta làm giá trị $x_1$ càng dương hoặc càng âm thì $x_1^2$ càng dương, mà theo hình thì giá trị h(x) là (-) nên dấu của $\\tilde{w}_1$ phải âm.\n",
    "\n",
    "Vậy câu trả lời đúng là [d] $\\tilde{w}_1 < 0, \\tilde{w}_2 >0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 3:** Ta có:\n",
    "$$\\Phi(1, x_1, x_2) = (1, x_1, x_2, x_1^2, x_1 x_2, x_2^2, x_1^3, x_1^2 x_2, x_1 x_2^2, x_2^3, x_1^4, x_1^3 x_2, x_1^2 x_2^2, x_1 x_2^3, x_2^4)$$\n",
    "$$\\Phi(1, x_1, x_2) = (z_0, z_1, z_2, z_3, z_4, z_5, z_6, z_7, z_8, z_9, z_{10}, z_{11}, z_{12}, z_{13}, z_{14})$$\n",
    "Suy ra $d_{VC} \\leq 14 + 1 = 15$\n",
    "\n",
    "Vậy đáp án là [c]. 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 4-7: Gradient descent\n",
    "Ta có dữ liệu đề bài cho:\n",
    "$$E(u, v) = (ue^v - 2ve^{-u})^2$$\n",
    "Với xuất phát điểm: $(u, v) = (1, 1)$.\n",
    "\n",
    "Tỷ lệ học tập $\\eta = 0.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 4:**\n",
    "\n",
    "Tính đạo hàm riêng của $E(u, v)$ theo biến u, tức tính $\\frac{\\delta E}{\\delta u}$.\n",
    "\n",
    "$\\frac{\\delta E}{\\delta u} = 2(ue^v - 2ve^{-u})(ue^v - 2ve^{-u})^{'} = 2(e^v + 2ve^{-u})(ue^v - 2ve^{-u})$.\n",
    "\n",
    "Vậy đáp án là [e]. $2(e^v + 2ve^{-u})(ue^v - 2ve^{-u})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 5:**\n",
    "Đếm số lần lặp của hàm cập nhập độ lỗi khi vừa mới nhỏ hơn $10^{-14}$ lần đầu tiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy library to all funtion \n",
    "import numpy as np\n",
    "\n",
    "#this is function to calc value of the error function E(u, v)\n",
    "def cost(u, v):\n",
    "    return (u*np.exp(v) - 2*v*np.exp(-u))**2\n",
    "\n",
    "#this is function to calc value of the gradient of E(u, v) as variable u\n",
    "def gradu(u, v):\n",
    "    return 2*(np.exp(v) + 2*v*np.exp(-u))*(u*np.exp(v) - 2*v*np.exp(-u))\n",
    "\n",
    "#this is funciton to calc value of the gradient of E(u, v) as variable v\n",
    "def gradv(u, v):\n",
    "    return 2*(u*np.exp(v) - 2*v*np.exp(-u))*(u*np.exp(v) - 2*np.exp(-u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the error E(u, v):  1.2086833944220747e-15\n",
      "iteration =  10\n"
     ]
    }
   ],
   "source": [
    "#this is function calc value of the error and iterations to go that value\n",
    "def GD(u, v, eta):\n",
    "    \"\"\"\n",
    "        parameter:\n",
    "            (u, v): start point\n",
    "            eta: learning rate\n",
    "        return:\n",
    "            x0: E(u, v)\n",
    "            iters: iterations\n",
    "    \"\"\"\n",
    "    #value of the start point (u, v)\n",
    "    x0 = cost(u, v)\n",
    "    iters = 0\n",
    "    \n",
    "    #calc value of the error and iters while value not leq 10^-14\n",
    "    while x0 > 1e-14:\n",
    "        iters += 1\n",
    "        #save value temp of the u and v\n",
    "        utmp = u\n",
    "        vtmp = v\n",
    "        #update value of the u and v as graident\n",
    "        u = utmp - eta*gradu(utmp, vtmp)\n",
    "        v = vtmp - eta*gradv(utmp, vtmp)\n",
    "        #update value of the error\n",
    "        x0 = cost(u, v)\n",
    "    \n",
    "    #Return value of the error and iterations\n",
    "    return x0, iters\n",
    "\n",
    "#question 5\n",
    "x, iters = GD(1, 1, 0.1)\n",
    "print(\"Value of the error E(u, v): \", x)\n",
    "print(\"iteration = \", iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đán án ra chính xác là 10, vậy câu trả lời là [d]. 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 6:** Tính giá trị của u và v, sau câu 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u, v) = ( 0.04473629039778207 ,  0.023958714099141746 )\n"
     ]
    }
   ],
   "source": [
    "#calc u and v wih problem 5\n",
    "def GDuv(u, v, eta):\n",
    "    x0 = cost(u, v)\n",
    "    \n",
    "    while x0 > 1e-14:\n",
    "        #save value temp of the u and v\n",
    "        utmp = u\n",
    "        vtmp = v\n",
    "        #update value of the u and v as graident\n",
    "        u = utmp - eta*gradu(utmp, vtmp)\n",
    "        v = vtmp - eta*gradv(utmp, vtmp)\n",
    "        x0 = cost(u, v)\n",
    "    \n",
    "    #return value of point (u, v) after update\n",
    "    return u, v\n",
    "\n",
    "#question 6\n",
    "u, v = GDuv(1, 1, 0.1)\n",
    "print (\"(u, v) = (\", u, \", \", v, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy đáp án chính xác là [e]. (0.045, 0.024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 7:** Tính già trị của E(u, v) sau 15 iteration tức là 30 bước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the error after 15 iteration is  1.8102516887519038\n"
     ]
    }
   ],
   "source": [
    "#calc value of the error after 15 iteration\n",
    "def GDAfter15Iteration(u, v, eta):\n",
    "    for iters in range(15):\n",
    "        #step 1\n",
    "        u = u - eta\n",
    "        #step 2\n",
    "        v = v - eta\n",
    "    \n",
    "    #return of the end result\n",
    "    return cost(u, v)\n",
    "\n",
    "#question 7\n",
    "error = GDAfter15Iteration(1, 1, 0.1)\n",
    "print(\"Value of the error after 15 iteration is \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá trị gần nhất trong các đáp án là [1]. $10^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 8-9: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm phát sinh ra `target_w`, vector tham số của f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1]*p2[0] - p1[0]*p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm phát sinh ra dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "        Y = np.sign(np.dot(X, target_w))\n",
    "        if (0 not in Y): # Good data\n",
    "            bad_data = False\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm huấn luyện logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X, Y, eta, threshold):\n",
    "    \"\"\"\n",
    "    parameters\n",
    "    ----------\n",
    "    X: numpy array, shape (N, 3)\n",
    "        The matrix of input vectors; the first column of the matrix is all ones.\n",
    "    Y: numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    eta: learning rate.\n",
    "    threshold: condition to stop trainning\n",
    "    returns\n",
    "    -------\n",
    "    w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    n_epochs : int\n",
    "        The number of update w\n",
    "    \"\"\"\n",
    "    w = np.zeros((X.shape[1], 1)) # Init weight\n",
    "    n_epochs = 0 #Init epoch\n",
    "    \n",
    "    # Run learning model logistic regression\n",
    "    while True:\n",
    "        #save weight of previous t\n",
    "        previous_w = np.copy(w)\n",
    "        #random to shuffle data\n",
    "        rand_idxs = np.random.permutation(X.shape[0])\n",
    "        for idx in rand_idxs:\n",
    "            #get one point in data\n",
    "            x = X[idx].reshape(X.shape[1], 1)\n",
    "            y = Y[idx][-1]\n",
    "            #calc gradient descent with one point (x, y) - in document, gradient has been calc with mean gradient\n",
    "            gradient = -y*x / (1.0 + np.exp(y*np.dot(w.T, x)))\n",
    "            #update weight\n",
    "            w = w - eta*gradient\n",
    "        #add one epochs\n",
    "        n_epochs += 1\n",
    "        #if distance of weigth(t) and previous(t-1) < thresold then break loop\n",
    "        if np.all(np.abs(w - previous_w) < threshold):\n",
    "            break\n",
    "    #return weight and number of epochs to train\n",
    "    return w, n_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hám tính độ lỗi sau khi tìm được w (cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyError(X, Y, w):\n",
    "    \"\"\"\n",
    "    parameters\n",
    "    ----------\n",
    "    X: numpy array, shape (N, 3)\n",
    "        The matrix of input vectors; the first column of the matrix is all ones.\n",
    "    Y: numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    return\n",
    "    ------\n",
    "    Ein: value of the error after we calc w from data\n",
    "    \"\"\"\n",
    "    Ein = []\n",
    "    \n",
    "    for idx in range(X.shape[0]):\n",
    "        x = X[idx].reshape(X.shape[1], 1)\n",
    "        y = Y[idx][-1]\n",
    "        # value of the error on one point (x, y)\n",
    "        Ein.append(np.log(1.0 + np.exp(-y*np.dot(w.T, x))))\n",
    "        \n",
    "    #return value error mean\n",
    "    return np.mean(Ein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 8, 9:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eout:  0.09902810558651985\n",
      "Epochs:  248.8\n"
     ]
    }
   ],
   "source": [
    "def Q8And9(N, numOfRun):\n",
    "    Eout = []\n",
    "    epochs = []\n",
    "    \n",
    "    for r in range(numOfRun):\n",
    "        X, Y = generate_data(N, generate_target_w())\n",
    "        \n",
    "        w, n_epochs = logisticRegression(X, Y, 0.01, 0.01)\n",
    "        \n",
    "        Eout.append(crossEntropyError(X, Y, w))\n",
    "        epochs.append(n_epochs)\n",
    "        \n",
    "    print(\"Eout: \", np.mean(Eout))\n",
    "    print(\"Epochs: \", np.mean(epochs))\n",
    "\n",
    "#question 8 and 9\n",
    "Q8And9(100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa vào kết quả sau 100 lần chạy thì ta kết luận\n",
    "\n",
    "Câu 8: [d]. 0.100\n",
    "\n",
    "Câu 9: [a]. 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 10: PLA as SGD\n",
    "\n",
    "Thuật toán học PLA cũng có thể dùng SGD vì:\n",
    "$$\\mathbf{w} \\leftarrow \\mathbf{w} + y^{(n)}\\mathbf{x}^{(n)}$$\n",
    "trong đó $\\mathbf{x}^{n}$ là một điểm phân loại sai, khi đó $sign(\\mathbf{w}.T\\mathbf{x}^{n}) =//= y^{n}$. Trong trường hợp này thì $y^{(n)} \\mathbf{w}^{T} \\mathbf{x}^{(n)} < 0$.\n",
    "\n",
    "Vì chúng ta muốn cập nhập trọng số các điểm không khớp cho tât cả các điểm nên chúng ta cần lấy tôi thiểu $min(0, y^{(n)} \\mathbf{w}^{T} \\mathbf{x}^{(n)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy đáp án là [e]. $-min(0, y^{(n)} \\mathbf{w}^{T} \\mathbf{x}^{(n)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
