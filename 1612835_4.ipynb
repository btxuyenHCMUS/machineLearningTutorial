{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 4\n",
    "Bùi Trọng Xuyến - 1612835\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 1-3: Generalization Error\n",
    "Theo đề bài thì ta có $N > d_{VC}$ nên ta sẽ xấp xỉ growfunction $m_{H}(N) \\approx N^{d_{VC}}$.\n",
    "\n",
    "\"Còn nếu $N < d_{VC}$ thì ta có $m_\\mathcal{H}(N) = (đã học)$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 1:**\n",
    "\n",
    "- \"95% confidence\" nghĩa là $\\delta = 0.05$, \"generalization error is at most 0.05\" nghĩa là $\\epsilon = 0.05$.\n",
    "- Tìm $N$ bằng cách giải phương trình sau: $\\epsilon = \\sqrt{\\frac{8}{N} ln \\frac{4m_\\mathcal{H}(2N)}{\\delta}}$.\n",
    "- Thay vì giải một cách khó khăn phương trình này, ta thế các kết quả $N$ vào và xem kết quả nào gần nhất với $\\epsilon$.\n",
    "\n",
    "Đáp án gần nhất chính là $N = 460,000$ Vậy chọn [d]. $460,000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 2:**\n",
    "\n",
    "Ta có các giá trị sau: $d_{VC} = 50$, $\\delta = 0.05$, $N = 10,000$.\n",
    "\n",
    "Đề bài yêu cầu tìm giá trị $\\epsilon$ nhỏ nhất.\n",
    "- [a]. $\\epsilon \\leq \\sqrt{\\frac{8}{N} ln\\frac{4m_\\mathcal{H}(2N)}{\\delta}} \\approx \\sqrt{\\frac{8}{N} ln\\frac{4(2N)^{d_{VC}}}{\\delta}}$\n",
    "- [b]. $\\epsilon \\leq \\sqrt{\\frac{2ln(2Nm_\\mathcal{H}(N))}{N}} + \\sqrt{\\frac{2}{N} ln\\frac{1}{\\delta}} + \\frac{1}{N} \\approx \\sqrt{\\frac{2ln(2NN^{d_{VC}})}{N}} + \\sqrt{\\frac{2}{N} ln\\frac{1}{\\delta}} + \\frac{1}{N}$\n",
    "- [c]. $\\epsilon \\leq \\sqrt{\\frac{1}{N}(2\\epsilon + ln\\frac{6m_\\mathcal{H}(2N)}{\\delta}}) \\Leftrightarrow \\epsilon^{2} - \\frac{2}{N}\\epsilon - \\frac{1}{N} ln\\frac{6m_\\mathcal{H}(2N)}{\\delta} \\leq 0 \\Leftrightarrow \\epsilon^{2} - \\frac{2}{N}\\epsilon - \\frac{1}{N} ln\\frac{6x2^{2N}}{\\delta} \\leq 0$\n",
    "- [d]. $\\epsilon \\leq \\sqrt{\\frac{1}{2N}(4\\epsilon(1 + \\epsilon) + ln\\frac{4m_\\mathcal{H}(N^{2})}{\\delta})} \\Leftrightarrow (1 - \\frac{2}{N})\\epsilon^{2} - \\frac{1}{2N}\\epsilon - \\frac{1}{2N} ln\\frac{4m_\\mathcal{H}(N^{2})}{\\delta} \\leq 0 \\Leftrightarrow (1 - \\frac{2}{N})\\epsilon^{2} - \\frac{1}{2N}\\epsilon - \\frac{1}{2N} ln\\frac{4x2^{N^{2}}}{\\delta} \\leq 0$\n",
    "\n",
    "Giải các bất phương trình trên bằng mathlab thì đáp án [d] cho giới hạn trên của $\\epsilon$ nhỏ nhất.\n",
    "\n",
    "Vậy đáp án cuối cùng là [d]. $\\epsilon \\leq \\sqrt{\\frac{1}{2N}(4\\epsilon(1 + \\epsilon) + ln\\frac{4m_\\mathcal{H}(N^{2})}{\\delta})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 3:**\n",
    "\n",
    "Tương tự như câu 2 nhưng với $N = 5 < d_{VC} = 50$ nên $m_\\mathcal{H}(N) = \\sum_{i=0}^{d_{VC}-1} C_{N}^{i} = 2^{N}$\n",
    "\n",
    "Giải như câu 2 bằng mathlab cho được đáp án [c].\n",
    "\n",
    "[c]. $\\epsilon \\leq \\sqrt{\\frac{1}{N}(2\\epsilon + ln\\frac{6m_\\mathcal{H}(2N)}{\\delta}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 4-7: Bias and Variance\n",
    "Theo đề bài ta có hàm phát sinh dữ liệu $f(x) = sin(\\pi x)$, với giá trị đầu vào có phân bố đều trong khoảng $[-1; 1]$.\n",
    "\n",
    "Theo như công thức đã học ta có $\\bar{g}(\\mathbf{x}) = \\mathbb{E}_\\mathcal{D}\\left[g^{(\\mathcal{D})}(\\mathbf{x})\\right]$ với $\\mathcal{D}$ là một tập dữ liệu có kích thước $N = 2$.\n",
    "\n",
    "Với các hypothesis thì việc tính trung bình các $g^{(\\mathcal{D})}$ tương đương với việc tính trung bình các trọng số của $g^{(\\mathcal{D})}$. Kết quả là $\\bar{g}(x) = \\bar{a}x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 4:**\n",
    "- Ta sẽ viết code một hàm phát sinh tập dũ liệu $\\mathcal{D}$ có kích thước $N$.\n",
    "- Vì hypothesis có dạng $h(x) = ax$ nên ta sẽ tìm a bằng cách gọi hàm huấn luyện linearRegression với ma trận input $\\mathbf{X}$ truyền vào là ma trận $(Nx1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_dataset(N):\n",
    "    X = np.random.uniform(-1, 1, (N, 1))\n",
    "    Y = np.sin(np.pi * X)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegression(X, Y):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        X: input matrix\n",
    "        Y: input vector value\n",
    "    return:\n",
    "        w: weight of hypothesis\n",
    "    \"\"\"\n",
    "    return np.dot(np.linalg.pinv(np.dot(X.T, X)), np.dot(X.T, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) =  1.4718678092807518 x\n"
     ]
    }
   ],
   "source": [
    "def Q4(N):\n",
    "    numOfRun = 1000\n",
    "    arrW = []\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        X, Y = generate_dataset(N)\n",
    "        w = linearRegression(X, Y)\n",
    "        \n",
    "        arrW.append(w[-1][-1])\n",
    "    \n",
    "    print(\"h(x) = \", np.mean(arrW), \"x\")\n",
    "\n",
    "#Result of question 4\n",
    "Q4(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả không giống với đáp án nên đáp án là [e]. None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 5:**Ta có công thức bias: $$bias = \\mathbb{E}_\\mathbf{x}\\left[(\\bar{g}(\\mathbf{x}) - f(\\mathbf{x}))^2\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias =  0.2772358830403026\n"
     ]
    }
   ],
   "source": [
    "def Q5(N):\n",
    "    \"\"\"\n",
    "        parameter:\n",
    "            N: Số dự liệu đầu vào của một hypothesis\n",
    "            \n",
    "        return:\n",
    "            bias: giá trị trung bình bình phương độ lỗi giữa gD(x) trung bình với giá trị thật\n",
    "     \n",
    "    \"\"\"\n",
    "    numOfRun = 1000 #Số lần lặp\n",
    "    inputX = [] #Ma trận lưu\n",
    "    inputY = [] #Ma trận lưu\n",
    "    arrW = [] #Mảng W\n",
    "    arrBias = [] #Mảng các giá trị bias\n",
    "    \n",
    "    #Tìm ra giá trị gD(x) trung bình\n",
    "    for i in range(numOfRun):\n",
    "        X, Y = generate_dataset(N)\n",
    "        #Lưu lại ma trận đầu vào\n",
    "        inputX.append(X)\n",
    "        inputY.append(Y)\n",
    "        # Tính toán gD(x)\n",
    "        w = linearRegression(X, Y)\n",
    "        arrW.append(w[-1][-1])\n",
    "    #gD(x) trung bình\n",
    "    meanW = np.mean(arrW)\n",
    "    \n",
    "    #Tính giá trị bias\n",
    "    for i in range(numOfRun):\n",
    "        #Tính bình phương độ lỗi giữa hypothesis với giá trị thật\n",
    "        bias = (meanW*inputX[i] - inputY[i])**2\n",
    "        arrBias.append(bias)\n",
    "    #Kết quả cần tìm là giá trị trung bình\n",
    "    print(\"bias = \", np.mean(arrBias))\n",
    "\n",
    "#Result of question 5\n",
    "Q5(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả gần nhất với 0.3 nên đáp án là [b]. 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 6:** Ta có công thức var:$$var =  \\mathbb{E}_\\mathbf{x}\\left[\\mathbb{E}_\\mathcal{D}\\left[(g^{(\\mathcal{D})}(\\mathbf{x}) - \\bar{g}(\\mathbf{x}))^2\\right]\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var =  0.21494534354458025\n"
     ]
    }
   ],
   "source": [
    "def Q6(N):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        N: số dữ liệu\n",
    "    return:\n",
    "        var: bình phương độ lỗi giữa trọng số tìm được với trọng số trung bình\n",
    "    \"\"\"\n",
    "    numOfRun = 1000\n",
    "    inputX = []\n",
    "    inputY = []\n",
    "    arrW = []\n",
    "    arrVar = []\n",
    "    \n",
    "    #Tính gD(x) trung bình\n",
    "    for i in range(numOfRun):\n",
    "        X,Y = generate_dataset(N)\n",
    "        #Lưu lại ma trận đầu vào\n",
    "        inputX.append(X)\n",
    "        inputY.append(Y)\n",
    "        #Tính W\n",
    "        w = linearRegression(X, Y)\n",
    "        \n",
    "        arrW.append(w[-1][-1])\n",
    "        \n",
    "    meanW = np.mean(arrW)\n",
    "    \n",
    "    #Tính var\n",
    "    for i in range(numOfRun):\n",
    "        #Tìm lại w\n",
    "        w = linearRegression(inputX[i], inputY[i])\n",
    "        #Tính giá trị của var theo công thức\n",
    "        var = (w[-1][-1]*inputX[i] - meanW*inputX[i])**2\n",
    "        \n",
    "        arrVar.append(var)\n",
    "    #Giá trị cuối cùng cần tìm là giá trị trung bình cả màng var\n",
    "    print(\"Var = \", np.mean(arrVar))\n",
    "    \n",
    "#Result of the question 6\n",
    "Q6(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả gần nhất với đáp án [a]. 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 7:**\n",
    "\n",
    "Tìm ra các $\\bar{g}(x)$, $bias$, $var$ cho các hypothesis của các câu.\n",
    "\n",
    "[a]. $h(x) = b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) =  1.2246467991473532e-16 x\n",
      "bias =  0.0\n",
      "var =  0.0\n"
     ]
    }
   ],
   "source": [
    "def Q7a(N):\n",
    "    numOfRun = 1000\n",
    "    inputX = []\n",
    "    inputY = []\n",
    "    arrW = []\n",
    "    arrBias = []\n",
    "    arrVar = []\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        X = np.ones((N, 1))\n",
    "        Y = np.sin(np.pi * X)\n",
    "        inputX.append(X)\n",
    "        inputY.append(Y)\n",
    "        \n",
    "        w = linearRegression(X, Y)\n",
    "        arrW.append(w[-1][-1])\n",
    "    \n",
    "    meanW = np.mean(arrW)\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        bias = (meanW*inputX[i] - inputY[i])**2\n",
    "        arrBias.append(bias)\n",
    "        \n",
    "        w = linearRegression(inputX[i], inputY[i])\n",
    "        var = (w[-1][-1]*inputX[i] - meanW*inputX[i])**2\n",
    "        arrVar.append(var)\n",
    "    \n",
    "    #show on\n",
    "    print(\"h(x) = \", meanW, \"x\")\n",
    "    print(\"bias = \", np.mean(arrBias))\n",
    "    print(\"var = \", np.mean(arrVar))\n",
    "    \n",
    "#Result of the question 7a\n",
    "Q7a(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[b]. $h(x) = ax$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) =  1.4161088002498081 x\n",
      "bias =  0.25664025916712874\n",
      "var =  0.19179941562409236\n"
     ]
    }
   ],
   "source": [
    "def Q7b(N):\n",
    "    numOfRun = 1000\n",
    "    inputX = []\n",
    "    inputY = []\n",
    "    arrW = []\n",
    "    arrBias = []\n",
    "    arrVar = []\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        X, Y = generate_dataset(N)\n",
    "        inputX.append(X)\n",
    "        inputY.append(Y)\n",
    "        \n",
    "        w = linearRegression(X, Y)\n",
    "        arrW.append(w[-1][-1])\n",
    "    \n",
    "    meanW = np.mean(arrW)\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        bias = (meanW*inputX[i] - inputY[i])**2\n",
    "        arrBias.append(bias)\n",
    "        \n",
    "        w = linearRegression(inputX[i], inputY[i])\n",
    "        var = (w[-1][-1]*inputX[i] - meanW*inputX[i])**2\n",
    "        arrVar.append(var)\n",
    "    \n",
    "    #show on\n",
    "    print(\"h(x) = \", meanW, \"x\")\n",
    "    print(\"bias = \", np.mean(arrBias))\n",
    "    print(\"var = \", np.mean(arrVar))\n",
    "    \n",
    "#Result of the question 7b\n",
    "Q7b(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[c]. $h(x) = ax + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) =  0.8324322576550057 x +  0.04311671886098914\n",
      "bias =  0.6575995316333194\n",
      "var =  3.3886683080858178\n"
     ]
    }
   ],
   "source": [
    "def Q7c(N):\n",
    "    numOfRun = 1000\n",
    "    inputX = []\n",
    "    inputY = []\n",
    "    arrA = []\n",
    "    arrB = []\n",
    "    arrBias = []\n",
    "    arrVar = []\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        X, Y = generate_dataset(N)\n",
    "        X = np.hstack((np.ones((N, 1)), X))\n",
    "        inputX.append(X)\n",
    "        inputY.append(Y)\n",
    "        \n",
    "        #Tìm w và tách thành 2 giá trị a và b\n",
    "        w = linearRegression(X, Y)\n",
    "        arrA.append(w[1][0])\n",
    "        arrB.append(w[0][0])\n",
    "    #Tính giá trị trung bình a và b\n",
    "    a = np.mean(arrA)\n",
    "    b = np.mean(arrB)\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        #Tính bias\n",
    "        bias = ((a*inputX[i] - b) - inputY[i])**2\n",
    "        arrBias.append(bias)\n",
    "        \n",
    "        #Tính variance\n",
    "        w = linearRegression(inputX[i], inputY[i])\n",
    "        var = ((w[1][0]*inputX[i] - w[0][0]) - (a*inputX[i] - b))**2\n",
    "        arrVar.append(var)\n",
    "    \n",
    "    #show on\n",
    "    print(\"h(x) = \", a, \"x + \", b)\n",
    "    print(\"bias = \", np.mean(arrBias))\n",
    "    print(\"var = \", np.mean(arrVar))\n",
    "\n",
    "#Result of the question 7c\n",
    "Q7c(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[d]/ $h(x) = ax^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) =  0.14259511978138012 x\n",
      "bias =  0.5043270157607703\n",
      "var =  0.2716364798571537\n"
     ]
    }
   ],
   "source": [
    "def Q7d(N):\n",
    "    numOfRun = 1000\n",
    "    inputX = []\n",
    "    inputY = []\n",
    "    arrW = []\n",
    "    arrBias = []\n",
    "    arrVar = []\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        X, Y = generate_dataset(N)\n",
    "        X = X**2\n",
    "        inputX.append(X)\n",
    "        inputY.append(Y)\n",
    "        \n",
    "        w = linearRegression(X, Y)\n",
    "        arrW.append(w[-1][-1])\n",
    "    \n",
    "    meanW = np.mean(arrW)\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        bias = (meanW*inputX[i] - inputY[i])**2\n",
    "        arrBias.append(bias)\n",
    "        \n",
    "        w = linearRegression(inputX[i], inputY[i])\n",
    "        var = (w[-1][-1]*inputX[i] - meanW*inputX[i])**2\n",
    "        arrVar.append(var)\n",
    "    \n",
    "    #show on\n",
    "    print(\"h(x) = \", meanW, \"x\")\n",
    "    print(\"bias = \", np.mean(arrBias))\n",
    "    print(\"var = \", np.mean(arrVar))\n",
    "    \n",
    "#Result of the question 7b\n",
    "Q7d(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[e]. $h(x) = ax^{2} + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) =  7.015697044466343 x +  0.5915143960304823\n",
      "bias =  24.704295131700594\n",
      "var =  67568.01991889639\n"
     ]
    }
   ],
   "source": [
    "def Q7e(N):\n",
    "    numOfRun = 1000\n",
    "    inputX = []\n",
    "    inputY = []\n",
    "    arrA = []\n",
    "    arrB = []\n",
    "    arrBias = []\n",
    "    arrVar = []\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        X, Y = generate_dataset(N)\n",
    "        X = X**2\n",
    "        X = np.hstack((np.ones((N, 1)), X))\n",
    "        inputX.append(X)\n",
    "        inputY.append(Y)\n",
    "        \n",
    "        #Tìm w và tách thành 2 giá trị a và b\n",
    "        w = linearRegression(X, Y)\n",
    "        arrA.append(w[1][0])\n",
    "        arrB.append(w[0][0])\n",
    "    #Tính giá trị trung bình a và b\n",
    "    a = np.mean(arrA)\n",
    "    b = np.mean(arrB)\n",
    "    \n",
    "    for i in range(numOfRun):\n",
    "        #Tính bias\n",
    "        bias = ((a*inputX[i] - b) - inputY[i])**2\n",
    "        arrBias.append(bias)\n",
    "        \n",
    "        #Tính variance\n",
    "        w = linearRegression(inputX[i], inputY[i])\n",
    "        var = ((w[1][0]*inputX[i] - w[0][0]) - (a*inputX[i] - b))**2\n",
    "        arrVar.append(var)\n",
    "    \n",
    "    #show on\n",
    "    print(\"h(x) = \", a, \"x + \", b)\n",
    "    print(\"bias = \", np.mean(arrBias))\n",
    "    print(\"var = \", np.mean(arrVar))\n",
    "\n",
    "#Result of the question 7c\n",
    "Q7e(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa vào các giá trị bias và variance của các hypothesis.\n",
    "\n",
    "Ta chọn giá trị cho bias và variance nhỏ nhất. [d] $h(x) = ax$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 8-10: VC Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 8:**\n",
    "\n",
    "Ta có $d_{VC}$ là giá trị $N$ nhỏ nhất mà ở đó grow function $m_\\mathcal{H}(N)$ chưa bị break, nghĩa là $m_\\mathcal{H}(N)$ vẫn đạt giá trị tối đa $2^{N}$.\n",
    "- $m_\\mathcal{H}(1) = 2$\n",
    "- giả sử $m_\\mathcal{H}(N)$ chưa bị break tức là $m_\\mathcal{H}(N) = 2^{N}$.\n",
    "- Suy ra $m_\\mathcal{H}(N+1) = 2m_\\mathcal{H}(N) - \\binom{N}{q} = 2.2^{N} - \\binom{N}{q} = 2^{N+1} - \\binom{N}{q}$\n",
    "\n",
    "Nhìn vào kết quả ta thấy khi $q \\leq N$ thì $m_\\mathcal{H}(N+1) \\neq 2^{N+1}$\n",
    "- Nên ta kết luận rằng $N = q$ là giá trị nhỏ nhất làm grow function bị break.\n",
    "\n",
    "Vậy kết quả cuối cùng là [c]. q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 9:**\n",
    "\n",
    "Ta có các tập hypothesis $\\mathcal{H}_{1}, \\mathcal{H}_{2}, ..., \\mathcal{H}_{K}$ có các giá trị $d_{VC}(\\mathcal{H}_{K})$ hữu hạn.\n",
    "\n",
    "Ta có tập hypothesis giao $\\cap_{k=1}^{K} \\mathcal{H}_{k}$ có $d_{VC}(\\cap_{k=1}^{K} \\mathcal{H}_{k}) = min\\{d_{VC}(\\mathcal{H}_{k})\\}_{k=1}^{K}$.\n",
    "\n",
    "Đường bao chính xác hơn là: $0 \\leq d_{VC}(\\cap_{k=1}^{K} \\mathcal{H}_{k}) \\leq min\\{d_{VC}(\\mathcal{H}_{k})\\}_{k=1}^{K}$.\n",
    "\n",
    "Vậy đáp án chính xác là [b]. $0 \\leq d_{VC}(\\cap_{k=1}^{K} \\mathcal{H}_{k}) \\leq min\\{d_{VC}(\\mathcal{H}_{k})\\}_{k=1}^{K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Câu 10:**\n",
    "\n",
    "Ta có các tập hypothesis $\\mathcal{H}_{1}, \\mathcal{H}_{2}, ..., \\mathcal{H}_{K}$ có các giá trị $d_{VC}(\\mathcal{H}_{K})$ hữu hạn.\n",
    "\n",
    "Ta có tập hypothesis giao $\\cap_{k=1}^{K} \\mathcal{H}_{k}$ có $d_{VC}(\\cap_{k=1}^{K} \\mathcal{H}_{k}) = max\\{d_{VC}(\\mathcal{H}_{k})\\}_{k=1}^{K}$.\n",
    "\n",
    "Ta đã có giới han dưới. còn việc tìm giới hạn trên em chưa tìm ra."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
